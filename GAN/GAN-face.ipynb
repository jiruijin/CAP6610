{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40aca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip data.zip #dataset for LFW Face Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# seed setting\n",
    "def same_seeds(seed):\n",
    "    # Python built-in random module\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(2022)\n",
    "workspace_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34540e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for CrypkoDataset\n",
    "\n",
    "class CrypkoDataset(Dataset):\n",
    "    def __init__(self, fnames, transform):\n",
    "        self.transform = transform\n",
    "        self.fnames = fnames\n",
    "        self.num_samples = len(self.fnames)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.fnames[idx]\n",
    "        img = torchvision.io.read_image(fname)\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "def get_dataset(root):\n",
    "    fnames = glob.glob(os.path.join(root, '*'))\n",
    "    compose = [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ]\n",
    "    transform = transforms.Compose(compose)\n",
    "    dataset = CrypkoDataset(fnames, transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset = get_dataset(os.path.join(workspace_dir, 'dataLFW'))\n",
    "\n",
    "images = [temp_dataset[i] for i in range(4)]\n",
    "grid_img = torchvision.utils.make_grid(images, nrow=4)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (batch, in_dim)\n",
    "    Output shape: (batch, 3, 64, 64)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, feature_dim=64):\n",
    "        super().__init__()\n",
    "    \n",
    "        #input: (batch, 100)\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, feature_dim * 8 * 4 * 4, bias=False),\n",
    "            nn.BatchNorm1d(feature_dim * 8 * 4 * 4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            self.dconv_bn_relu(feature_dim * 8, feature_dim * 4),               #(batch, feature_dim * 16, 8, 8)     \n",
    "            self.dconv_bn_relu(feature_dim * 4, feature_dim * 2),               #(batch, feature_dim * 16, 16, 16)     \n",
    "            self.dconv_bn_relu(feature_dim * 2, feature_dim),                   #(batch, feature_dim * 16, 32, 32)     \n",
    "        )\n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(feature_dim, 3, kernel_size=5, stride=2,\n",
    "                               padding=2, output_padding=1, bias=False),\n",
    "            nn.Tanh()   \n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "    def dconv_bn_relu(self, in_dim, out_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_dim, out_dim, kernel_size=5, stride=2,\n",
    "                               padding=2, output_padding=1, bias=False),        #double height and width\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.l1(x)\n",
    "        y = y.view(y.size(0), -1, 4, 4)\n",
    "        y = self.l2(y)\n",
    "        y = self.l3(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (batch, 3, 64, 64)\n",
    "    Output shape: (batch)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, feature_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "            \n",
    "        #input: (batch, 3, 64, 64)\n",
    "        \"\"\"\n",
    "        NOTE FOR SETTING DISCRIMINATOR:\n",
    "\n",
    "        Remove last sigmoid layer for WGAN\n",
    "        \"\"\"\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, feature_dim, kernel_size=4, stride=2, padding=1), #(batch, 3, 32, 32)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self.conv_bn_lrelu(feature_dim, feature_dim * 2),                   #(batch, 3, 16, 16)\n",
    "            self.conv_bn_lrelu(feature_dim * 2, feature_dim * 4),               #(batch, 3, 8, 8)\n",
    "            self.conv_bn_lrelu(feature_dim * 4, feature_dim * 8),               #(batch, 3, 4, 4)\n",
    "            nn.Conv2d(feature_dim * 8, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "    def conv_bn_lrelu(self, in_dim, out_dim):\n",
    "        \"\"\"\n",
    "        NOTE FOR SETTING DISCRIMINATOR:\n",
    "\n",
    "        You can't use nn.Batchnorm for WGAN-GP\n",
    "        Use nn.InstanceNorm2d instead\n",
    "        \"\"\"\n",
    "\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.l1(x)\n",
    "        y = y.view(-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting for weight init function\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a77fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerGAN():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        \n",
    "        self.G = Generator(100)\n",
    "        self.D = Discriminator(3)\n",
    "        \n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        \"\"\"\n",
    "        NOTE FOR SETTING OPTIMIZER:\n",
    "\n",
    "        GAN: use Adam optimizer\n",
    "        WGAN: use RMSprop optimizer\n",
    "        WGAN-GP: use Adam optimizer \n",
    "        \"\"\"\n",
    "        self.opt_D = torch.optim.Adam(self.D.parameters(), lr=self.config[\"lr\"], betas=(0.5, 0.999))\n",
    "        self.opt_G = torch.optim.Adam(self.G.parameters(), lr=self.config[\"lr\"], betas=(0.5, 0.999))\n",
    "        \n",
    "        self.dataloader = None\n",
    "        self.log_dir = os.path.join(self.config[\"workspace_dir\"], 'logs')\n",
    "        self.ckpt_dir = os.path.join(self.config[\"workspace_dir\"], 'checkpoints')\n",
    "        \n",
    "        FORMAT = '%(asctime)s - %(levelname)s: %(message)s'\n",
    "        logging.basicConfig(level=logging.INFO, \n",
    "                            format=FORMAT,\n",
    "                            datefmt='%Y-%m-%d %H:%M')\n",
    "        \n",
    "        self.steps = 0\n",
    "        self.z_samples = Variable(torch.randn(100, self.config[\"z_dim\"])).cuda()\n",
    "        \n",
    "    def prepare_environment(self):\n",
    "        \"\"\"\n",
    "        Use this funciton to prepare function\n",
    "        \"\"\"\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "        os.makedirs(self.ckpt_dir, exist_ok=True)\n",
    "        \n",
    "        # update dir by time\n",
    "        time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        self.log_dir = os.path.join(self.log_dir, time+f'_{self.config[\"model_type\"]}')\n",
    "        self.ckpt_dir = os.path.join(self.ckpt_dir, time+f'_{self.config[\"model_type\"]}')\n",
    "        os.makedirs(self.log_dir)\n",
    "        os.makedirs(self.ckpt_dir)\n",
    "        \n",
    "        # create dataset by the above function\n",
    "        dataset = get_dataset(os.path.join(self.config[\"workspace_dir\"], 'dataLFW'))\n",
    "        self.dataloader = DataLoader(dataset, batch_size=self.config[\"batch_size\"], shuffle=True, num_workers=2)\n",
    "        \n",
    "        # model preparation\n",
    "        self.G = self.G.cuda()\n",
    "        self.D = self.D.cuda()\n",
    "        self.G.train()\n",
    "        self.D.train()\n",
    "    def gp(self):\n",
    "        \"\"\"\n",
    "        Implement gradient penalty function\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Use this function to train generator and discriminator\n",
    "        \"\"\"\n",
    "        self.prepare_environment()\n",
    "        \n",
    "        for e, epoch in enumerate(range(self.config[\"n_epoch\"])):\n",
    "            progress_bar = tqdm(self.dataloader)\n",
    "            progress_bar.set_description(f\"Epoch {e+1}\")\n",
    "            for i, data in enumerate(progress_bar):\n",
    "                imgs = data.cuda()\n",
    "                bs = imgs.size(0)\n",
    "\n",
    "                # *********************\n",
    "                # *    Train D        *\n",
    "                # *********************\n",
    "                z = Variable(torch.randn(bs, self.config[\"z_dim\"])).cuda()\n",
    "                r_imgs = Variable(imgs).cuda()\n",
    "                f_imgs = self.G(z)\n",
    "                r_label = torch.ones((bs)).cuda()\n",
    "                f_label = torch.zeros((bs)).cuda()\n",
    "\n",
    "\n",
    "                # Discriminator forwarding\n",
    "                r_logit = self.D(r_imgs)\n",
    "                f_logit = self.D(f_imgs)\n",
    "\n",
    "                \"\"\"\n",
    "                NOTE FOR SETTING DISCRIMINATOR LOSS:\n",
    "                \n",
    "                GAN: \n",
    "                    loss_D = (r_loss + f_loss)/2\n",
    "                WGAN: \n",
    "                    loss_D = -torch.mean(r_logit) + torch.mean(f_logit)\n",
    "                WGAN-GP: \n",
    "                    gradient_penalty = self.gp(r_imgs, f_imgs)\n",
    "                    loss_D = -torch.mean(r_logit) + torch.mean(f_logit) + gradient_penalty\n",
    "                \"\"\"\n",
    "                # Loss for discriminator\n",
    "                r_loss = self.loss(r_logit, r_label)\n",
    "                f_loss = self.loss(f_logit, f_label)\n",
    "                loss_D = (r_loss + f_loss) / 2\n",
    "\n",
    "                # Discriminator backwarding\n",
    "                self.D.zero_grad()\n",
    "                loss_D.backward()\n",
    "                self.opt_D.step()\n",
    "\n",
    "                \"\"\"\n",
    "                NOTE FOR SETTING WEIGHT CLIP:\n",
    "                \n",
    "                WGAN: below code\n",
    "                \"\"\"\n",
    "                # for p in self.D.parameters():\n",
    "                #     p.data.clamp_(-self.config[\"clip_value\"], self.config[\"clip_value\"])\n",
    "\n",
    "\n",
    "\n",
    "                # *********************\n",
    "                # *    Train G        *\n",
    "                # *********************\n",
    "                if self.steps % self.config[\"n_critic\"] == 0:\n",
    "                    # Generate some fake images.\n",
    "                    z = Variable(torch.randn(bs, self.config[\"z_dim\"])).cuda()\n",
    "                    f_imgs = self.G(z)\n",
    "\n",
    "                    # Generator forwarding\n",
    "                    f_logit = self.D(f_imgs)\n",
    "\n",
    "\n",
    "                    \"\"\"\n",
    "                    NOTE FOR SETTING LOSS FOR GENERATOR:\n",
    "                    \n",
    "                    GAN: loss_G = self.loss(f_logit, r_label)\n",
    "                    WGAN: loss_G = -torch.mean(self.D(f_imgs))\n",
    "                    WGAN-GP: loss_G = -torch.mean(self.D(f_imgs))\n",
    "                    \"\"\"\n",
    "                    # Loss for the generator.\n",
    "                    loss_G = self.loss(f_logit, r_label)\n",
    "\n",
    "                    # Generator backwarding\n",
    "                    self.G.zero_grad()\n",
    "                    loss_G.backward()\n",
    "                    self.opt_G.step()\n",
    "                    \n",
    "                if self.steps % 10 == 0:\n",
    "                    progress_bar.set_postfix(loss_G=loss_G.item(), loss_D=loss_D.item())\n",
    "                self.steps += 1\n",
    "\n",
    "            self.G.eval()\n",
    "            f_imgs_sample = (self.G(self.z_samples).data + 1) / 2.0\n",
    "            filename = os.path.join(self.log_dir, f'Epoch_{epoch+1:03d}.jpg')\n",
    "            torchvision.utils.save_image(f_imgs_sample, filename, nrow=10)\n",
    "            logging.info(f'Save some samples to {filename}.')\n",
    "\n",
    "            # Show some images during training.\n",
    "            grid_img = torchvision.utils.make_grid(f_imgs_sample.cpu(), nrow=10)\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.imshow(grid_img.permute(1, 2, 0))\n",
    "            plt.show()\n",
    "\n",
    "            self.G.train()\n",
    "\n",
    "            if (e+1) % 5 == 0 or e == 0:\n",
    "                # Save the checkpoints.\n",
    "                torch.save(self.G.state_dict(), os.path.join(self.ckpt_dir, f'G_{e}.pth'))\n",
    "                torch.save(self.D.state_dict(), os.path.join(self.ckpt_dir, f'D_{e}.pth'))\n",
    "\n",
    "        logging.info('Finish training')\n",
    "\n",
    "    def inference(self, G_path, n_generate=1000, n_output=30, show=False):\n",
    "        \"\"\"\n",
    "        1. G_path is the path for Generator ckpt\n",
    "        2. You can use this function to generate final answer\n",
    "        \"\"\"\n",
    "\n",
    "        self.G.load_state_dict(torch.load(G_path))\n",
    "        self.G.cuda()\n",
    "        self.G.eval()\n",
    "        z = Variable(torch.randn(n_generate, self.config[\"z_dim\"])).cuda()\n",
    "        imgs = (self.G(z).data + 1) / 2.0\n",
    "        \n",
    "        os.makedirs('output', exist_ok=True)\n",
    "        for i in range(n_generate):\n",
    "            torchvision.utils.save_image(imgs[i], f'output/{i+1}.jpg')\n",
    "        \n",
    "        if show:\n",
    "            row, col = n_output//10 + 1, 10\n",
    "            grid_img = torchvision.utils.make_grid(imgs[:n_output].cpu(), nrow=row)\n",
    "            plt.figure(figsize=(row, col))\n",
    "            plt.imshow(grid_img.permute(1, 2, 0))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bdae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_type\": \"GAN\",\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 1e-4,\n",
    "    \"n_epoch\": 100,\n",
    "    \"n_critic\": 1,\n",
    "    \"z_dim\": 100,\n",
    "    \"workspace_dir\": workspace_dir, # define in the environment setting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerGAN(config)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
